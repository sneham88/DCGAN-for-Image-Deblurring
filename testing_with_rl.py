# -*- coding: utf-8 -*-
"""testing with RL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nPNzxQlaehzetqeMtTYOZMQIfIMll4m5

### Import Libraries
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Add, UpSampling2D, Conv2D, Conv2DTranspose, BatchNormalization, Activation, Lambda, Flatten, GlobalAveragePooling2D, Dense
from tensorflow.keras.optimizers import Adam
from keras.callbacks import TensorBoard

from PIL import Image
from glob import glob
import os

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

"""### Load Dataset"""

from google.colab import drive
drive.mount('/content/drive')

"""### Defining the RL Algorithm"""

# Define PSF as a Gaussian Kernel
def gaussian_psf(kernel_size, sigma):
    ax = torch.arange(-kernel_size // 2 + 1., kernel_size // 2 + 1.)
    xx, yy = torch.meshgrid([ax, ax], indexing="ij")
    kernel = torch.exp(-0.5 * (xx**2 + yy**2) / sigma**2)
    kernel /= kernel.sum()
    return kernel

def richardson_lucy_rgb_torch(observed, psf, num_iterations=50, clip=True):

    assert observed.ndim == 3 and observed.shape[0] == 3, "Observed image should have shape (3, H, W)"
    assert psf.ndim == 2, "PSF should be a 2D tensor"

    estimated = observed.clone()

    # Flip the PSF for convolution
    psf_flip = torch.flip(psf, dims=(-2, -1))

    # Reshape PSF for conv2d
    psf = psf.unsqueeze(0).unsqueeze(0)
    psf_flip = psf_flip.unsqueeze(0).unsqueeze(0)

    for _ in range(num_iterations):
        for c in range(3):  # For each color channel (R, G, B)
            channel = estimated[c:c+1]  # (1, H, W)

            # Convolve with PSF
            convolved = F.conv2d(channel.unsqueeze(0), psf, padding='same').squeeze(0)

            # Avoid divide by zero
            convolved = torch.clamp(convolved, min=1e-8)

            # Ratio: (observed / (PSF * estimate))
            ratio = observed[c:c+1] / convolved

            # Backproject using flipped PSF
            backprojected = F.conv2d(ratio.unsqueeze(0), psf_flip, padding='same').squeeze(0)

            # Update estimated image
            estimated[c] *= backprojected.squeeze(0)

        if clip:
            estimated = torch.clamp(estimated, 0, 1)

    return estimated

"""### Load and Save Images"""

def load_image_as_tensor(image_path):
    image = Image.open(image_path).convert('RGB')
    image_np = np.asarray(image) / 255.0  # Normalize to [0, 1]
    image_tensor = torch.tensor(image_np, dtype=torch.float32).permute(2, 0, 1)  # (H, W, 3) -> (3, H, W)
    return image_tensor, image

def save_tensor_as_image(tensor, output_path):
    tensor = torch.clamp(tensor, 0, 1)  # Ensure values are valid for images
    image_np = tensor.permute(1, 2, 0).cpu().numpy()  # (3, H, W) -> (H, W, 3)
    image_np = (image_np * 255).astype(np.uint8)  # Convert to uint8
    Image.fromarray(image_np).save(output_path)

"""### RL Deconvolution on Gaussian Blur"""

# Define Input & Output Paths for Preprocessed Images
input_folder = "/content/drive/My Drive/FYP 2025/gaussian blurred images kernel setting 2 (test images)"
output_folder = "/content/drive/My Drive/FYP 2025/gaussian rl deconvolved test images"
os.makedirs(output_folder, exist_ok=True)

# Load PSF
device = 'cuda' if torch.cuda.is_available() else 'cpu'
psf = gaussian_psf(100, 10).to(device)

# --- Apply RL Deconvolution to Each Image ---
for filename in os.listdir(input_folder):
    if filename.endswith(".tif") or filename.endswith(".png"):
        input_path = os.path.join(input_folder, filename)

        # Convert all outputs to .tif
        base_filename = os.path.splitext(filename)[0]
        output_path = os.path.join(output_folder, base_filename + '.tif')

        print(f"Processing {filename}...")

        observed, _ = load_image_as_tensor(input_path)
        observed = observed.to(device)

        restored = richardson_lucy_rgb_torch(observed, psf, num_iterations=10)

        # Save Output Image as .tif
        save_tensor_as_image(restored, output_path)
        print(f"Saved RL-preprocessed image: {output_path}")

# Cleanup: Remove any .png files in the output folder (if previously created)
for file in os.listdir(output_folder):
    if file.endswith(".png"):
        png_path = os.path.join(output_folder, file)
        os.remove(png_path)
        print(f"Removed duplicate PNG: {png_path}")

print("Preprocessing complete. RL-processed images saved as .tif for DCGAN training.")

"""## Testing: Gaussian Blurs

#### Load Model, Blurry & Sharp Dataset
"""

from google.colab import drive
drive.mount('/content/drive')

model_path = "/content/drive/My Drive/FYP 2025/RL Preprocessed DCGAN/DCGAN_training_epochs/generator_epoch_40.keras"

preprocessed_folder = "/content/drive/My Drive/FYP 2025/gaussian rl deconvolved test images"
sharp_folder = "/content/drive/My Drive/FYP 2025/test high quality satellite images (.tif)"

import keras

keras.config.enable_unsafe_deserialization()
generator = tf.keras.models.load_model(model_path, compile=False)

"""#### Helper Functions"""

def denormalize_images(images):
    images = (images + 1.0) * 127.5
    return np.clip(images, 0, 255).astype(np.uint8)

def preprocess_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_COLOR)
    if img is None:
        raise FileNotFoundError(f"Image not found: {img_path}")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (256, 256))
    img = img.astype(np.float32) / 127.5 - 1  # Normalize to [-1, 1]
    return img

"""### Define PSNR, SSIM & LPIPS Metrics"""

pip install lpips --no-deps

from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import lpips

"""#### Evaluation Loop"""

def evaluate_generator(generator, blur_folder, sharp_folder):
    import torch
    import lpips

    # Initialize LPIPS (use 'alex' or 'vgg' for backbone)
    lpips_model = lpips.LPIPS(net='vgg').to('cuda' if torch.cuda.is_available() else 'cpu')
    lpips_model.eval()

    blur_files = sorted(os.listdir(blur_folder))
    psnr_scores, ssim_scores, lpips_scores = [], [], []

    for blur_file in blur_files:
        sharp_path = os.path.join(sharp_folder, blur_file)
        blur_path = os.path.join(blur_folder, blur_file)

        if not os.path.exists(sharp_path):
            print(f"⚠️ Skipping: No matching sharp image for {blur_file}")
            continue

        sharp_img = preprocess_image(sharp_path)
        blurry_img = preprocess_image(blur_path)

        input_tensor = np.expand_dims(blurry_img, axis=0)
        generated_img = generator.predict(input_tensor)[0]

        # Denormalize to [0, 255] for PSNR/SSIM
        generated_img_255 = denormalize_images(generated_img)
        sharp_img_255 = denormalize_images(sharp_img)

        # Metrics: PSNR & SSIM
        psnr_score = psnr(sharp_img_255, generated_img_255, data_range=255)
        ssim_score = ssim(sharp_img_255, generated_img_255, channel_axis=-1, data_range=255)

        # LPIPS requires tensors normalized to [-1, 1] and shape [1, 3, H, W]
        gen_tensor = torch.tensor(generated_img).permute(2, 0, 1).unsqueeze(0).to(torch.float32)
        sharp_tensor = torch.tensor(sharp_img).permute(2, 0, 1).unsqueeze(0).to(torch.float32)

        # Move to GPU if available
        if torch.cuda.is_available():
            gen_tensor = gen_tensor.cuda()
            sharp_tensor = sharp_tensor.cuda()

        # Compute LPIPS
        with torch.no_grad():
            lpips_score = lpips_model(gen_tensor, sharp_tensor).item()

        # Append scores
        psnr_scores.append(psnr_score)
        ssim_scores.append(ssim_score)
        lpips_scores.append(lpips_score)

    print("Evaluation on: Gaussian Kernel Setting 2")
    print(f"   Average PSNR score:  {np.mean(psnr_scores):.2f} dB")
    print(f"   Average SSIM score:  {np.mean(ssim_scores):.4f}")
    print(f"   Average LPIPS score: {np.mean(lpips_scores):.4f}")
    print(f"   Samples Evaluated:   {len(psnr_scores)}\n")

# Run evaluation
evaluate_generator(generator, preprocessed_folder, sharp_folder)

"""#### Plot Results - Linear Deblurring"""

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import cv2

# === Function to Display Deblurring Results ===
def display_sample_outputs(generator, blur_dir, sharp_dir, sample_filenames, title="Sample Output Comparison"):
    print("\n" + title + "\n")

    n = len(sample_filenames)
    fig, axs = plt.subplots(n, 3, figsize=(14, 4 * n))

    # Ensure axs is always 2D for consistent indexing
    if n == 1:
        axs = np.expand_dims(axs, axis=0)

    for i, filename in enumerate(sample_filenames):
        blur_path = os.path.join(blur_dir, filename)
        sharp_path = os.path.join(sharp_dir, filename)

        blurry = preprocess_image(blur_path)
        sharp = preprocess_image(sharp_path)
        generated = generator(tf.expand_dims(blurry, 0), training=False)[0].numpy()
        print(f"\n[DEBUG] {filename}")
        print("Input sum:     ", np.sum(blurry))
        print("Generated sum: ", np.sum(generated))
        print("Difference sum:", np.sum(np.abs(blurry - generated)))

        # Denormalize for visualization
        blurry_vis = denormalize_images(blurry)
        generated_vis = denormalize_images(generated)
        sharp_vis = denormalize_images(sharp)

        axs[i, 0].imshow(blurry_vis)
        axs[i, 0].set_title("Blurry Input")
        axs[i, 0].axis('off')

        axs[i, 1].imshow(generated_vis)
        axs[i, 1].set_title("Generated Output")
        axs[i, 1].axis('off')

        axs[i, 2].imshow(sharp_vis)
        axs[i, 2].set_title("Sharp Ground Truth")
        axs[i, 2].axis('off')

    plt.tight_layout()
    plt.show()

# Paths
blurry_folder = "/content/drive/My Drive/FYP 2025/gaussian blurred images kernel setting 2 (test images)"
sharp_folder = "/content/drive/My Drive/FYP 2025/test high quality satellite images (.tif)"

# Select samples (ensure they exist in both blurry and sharp folders)
samples_gaussian = ["1 a).tif", "12.tif", "55.tif"]

# Display comparison
display_sample_outputs(generator, blurry_folder, sharp_folder, samples_gaussian, title="Gaussian Blur - Sample Outputs")

"""## Testing: Zemax Blurs"""

from google.colab import drive
drive.mount('/content/drive')

"""### Apply RL Deconvolution to Test Images (Paraxial Lens)"""

# Define Input & Output Paths for Preprocessed Images
input_folder = "/content/drive/My Drive/FYP 2025/Zemax Test Images (Paraxial Lens)"
output_folder = "/content/drive/My Drive/FYP 2025/paraxial lens rl deconvolved test images"
os.makedirs(output_folder, exist_ok=True)

# Load PSF
device = 'cuda' if torch.cuda.is_available() else 'cpu'
psf = gaussian_psf(23, 3.48).to(device)

# --- Apply RL Deconvolution to Each Image ---
for filename in os.listdir(input_folder):
    if filename.endswith(".tif") or filename.endswith(".png"):
        input_path = os.path.join(input_folder, filename)
        output_path = os.path.join(output_folder, filename)  # Keep original extension

        print(f"Processing {filename}...")

        observed, _ = load_image_as_tensor(input_path)
        observed = observed.to(device)

        restored = richardson_lucy_rgb_torch(observed, psf, num_iterations=10)

        # Save Output Image in .tif format
        save_tensor_as_image(restored, output_path)
        print(f"Saved RL-preprocessed image: {output_path}")

for f in os.listdir(output_folder):
    if f.endswith(".png"):
        os.remove(os.path.join(output_folder, f))
        # print(f"Deleted leftover PNG: {f}")

print("Preprocessing complete. RL-processed images saved for DCGAN training.")

"""### Apply RL Convolution to Test Images (Plano Convex Lens)"""

# Define Input & Output Paths for Preprocessed Images
input_folder = "/content/drive/My Drive/FYP 2025/Zemax Test Images (Plano Convex Lens)"
output_folder = "/content/drive/My Drive/FYP 2025/plano convex lens rl deconvolved test images"
os.makedirs(output_folder, exist_ok=True)

# Load PSF
device = 'cuda' if torch.cuda.is_available() else 'cpu'
# print(f"Using device: {device}")
psf = gaussian_psf(33, 5.23).to(device)

# --- Apply RL Deconvolution to Each Image ---
for filename in os.listdir(input_folder):
    if filename.endswith(".tif") or filename.endswith(".png"):
        input_path = os.path.join(input_folder, filename)
        output_path = os.path.join(output_folder, filename)  # Keep original extension

        print(f"Processing {filename}...")

        observed, _ = load_image_as_tensor(input_path)
        observed = observed.to(device)

        restored = richardson_lucy_rgb_torch(observed, psf, num_iterations=10)

        # Save Output Image in .tif format
        save_tensor_as_image(restored, output_path)
        print(f"Saved RL-preprocessed image: {output_path}")

for f in os.listdir(output_folder):
    if f.endswith(".png"):
        os.remove(os.path.join(output_folder, f))
        # print(f"Deleted leftover PNG: {f}")

print("Preprocessing complete. RL-processed images saved for DCGAN training.")

"""### Testing on Zemax Blurry Images

#### Load Blurry and Sharp Dataset
"""

model_path = "/content/drive/My Drive/FYP 2025/RL Preprocessed DCGAN/DCGAN_training_epochs/generator_epoch_40.keras"

test_groups = {
    "Paraxial Aberration": "/content/drive/My Drive/FYP 2025/paraxial lens rl deconvolved test images",
    "Plano Convex Aberration": "/content/drive/My Drive/FYP 2025/plano convex lens rl deconvolved test images",
}
sharp_folder = "/content/drive/My Drive/FYP 2025/test high quality satellite images (.tif)"

import keras

keras.config.enable_unsafe_deserialization()
generator = tf.keras.models.load_model(model_path, compile=False)

"""#### Loop Through Each Blur Group"""

# Initialize LPIPS once (outside function if called multiple times)
lpips_model = lpips.LPIPS(net='vgg').to('cuda' if torch.cuda.is_available() else 'cpu')
lpips_model.eval()

def evaluate_generator_on_test_groups_by_filename(generator, test_groups, sharp_folder):
    for group_name, blur_folder in test_groups.items():
        blur_files = sorted(os.listdir(blur_folder))
        psnr_scores, ssim_scores, lpips_scores = [], [], []

        for blur_file in blur_files:
            sharp_path = os.path.join(sharp_folder, blur_file)
            blur_path = os.path.join(blur_folder, blur_file)

            if not os.path.exists(sharp_path):
                print(f"⚠️ Skipping: No matching sharp image for {blur_file}")
                continue

            sharp_img = preprocess_image(sharp_path)    # normalized [-1, 1]
            blurry_img = preprocess_image(blur_path)    # normalized [-1, 1]

            input_tensor = np.expand_dims(blurry_img, axis=0)
            generated_img = generator.predict(input_tensor)[0]

            # Denormalize for PSNR & SSIM
            generated_img_255 = denormalize_images(generated_img)
            sharp_img_255 = denormalize_images(sharp_img)

            # PSNR & SSIM
            psnr_score = psnr(sharp_img_255, generated_img_255, data_range=255)
            ssim_score = ssim(sharp_img_255, generated_img_255, channel_axis=-1, data_range=255)

            # LPIPS requires tensors in [-1, 1] range, [B, C, H, W]
            gen_tensor = torch.tensor(generated_img).permute(2, 0, 1).unsqueeze(0).float()
            sharp_tensor = torch.tensor(sharp_img).permute(2, 0, 1).unsqueeze(0).float()

            if torch.cuda.is_available():
                gen_tensor = gen_tensor.cuda()
                sharp_tensor = sharp_tensor.cuda()

            with torch.no_grad():
                lpips_score = lpips_model(gen_tensor, sharp_tensor).item()

            # Append scores
            psnr_scores.append(psnr_score)
            ssim_scores.append(ssim_score)
            lpips_scores.append(lpips_score)

        # Print results for this group
        print(f"{group_name}")
        print(f"   Average PSNR score:  {np.mean(psnr_scores):.2f} dB")
        print(f"   Average SSIM score:  {np.mean(ssim_scores):.4f}")
        print(f"   Average LPIPS score: {np.mean(lpips_scores):.4f}")
        print(f"   Samples Evaluated:   {len(psnr_scores)}\n")

# Run Evaluation
evaluate_generator_on_test_groups_by_filename(generator, test_groups, sharp_folder)

"""#### Plot Results - Nonlinear Deblurring"""

import matplotlib.pyplot as plt
import cv2

def display_sample_outputs(generator, blur_dir, sharp_dir, sample_filenames, title="Sample Output Comparison"):
    import matplotlib.pyplot as plt

    print("\n" + title + "\n")  # Blank line above title

    n = len(sample_filenames)
    fig, axs = plt.subplots(n, 3, figsize=(12, 4 * n))

    # Handle the case when only 1 image is given
    if n == 1:
        axs = np.expand_dims(axs, axis=0)

    for i, filename in enumerate(sample_filenames):
        blur_path = os.path.join(blur_dir, filename)
        sharp_path = os.path.join(sharp_dir, filename)

        blurry = preprocess_image(blur_path)
        sharp = preprocess_image(sharp_path)

        generated = generator(tf.expand_dims(blurry, 0), training=False)[0].numpy()

        # Denormalize for display
        blurry_vis = denormalize_images(blurry)
        generated_vis = denormalize_images(generated)
        sharp_vis = denormalize_images(sharp)

        axs[i, 0].imshow(blurry_vis)
        axs[i, 0].set_title("Blurry Input")
        axs[i, 0].axis('off')

        axs[i, 1].imshow(generated_vis)
        axs[i, 1].set_title("Generated Output")
        axs[i, 1].axis('off')

        axs[i, 2].imshow(sharp_vis)
        axs[i, 2].set_title("Sharp Ground Truth")
        axs[i, 2].axis('off')

    plt.tight_layout()
    plt.show()

# Select a few filenames that exist in the folder (must be present in both blurry and sharp)
samples_blur1 = ["1 a).tif"]
samples_blur2 = ["1 b).tif"]
samples_blur3 = ["1 c).tif"]

# Display side-by-side comparisons
display_sample_outputs(generator, test_groups["Paraxial Aberration"], sharp_folder, samples_blur1, title="Paraxial Aberration - Sample Outputs")
display_sample_outputs(generator, test_groups["Plano Convex Aberration"], sharp_folder, samples_blur2, title="Plano Convex Aberration - Sample Outputs")
display_sample_outputs(generator, test_groups["Biconvex Aberration"], sharp_folder, samples_blur3, title="Biconvex Aberration - Sample Outputs")

"""#### END"""