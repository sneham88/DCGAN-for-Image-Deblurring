{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392ab85f-ce2e-46d9-bac6-11757df97337",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb0447ad-b49e-4b27-903c-7d9ab13c6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import lpips\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43198c0-cfb0-480e-ab1c-af613b19d62b",
   "metadata": {},
   "source": [
    "### Import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e8494bd-989b-47a4-97b4-3eee3a2edc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d22d3-ef35-44de-beeb-6868fb171881",
   "metadata": {},
   "source": [
    "#### Gaussian Blur Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b19ff41d-f681-41ec-8cee-8a24594fd2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\sneha\\anaconda\\envs\\gpu_env\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n",
      "\n",
      "=== Evaluation over 77 images ===\n",
      "Average PSNR:  10.88 dB\n",
      "Average SSIM:  0.2171\n",
      "Average LPIPS: 0.8315\n"
     ]
    }
   ],
   "source": [
    "# === Set your directories ===\n",
    "ground_truth_dir = r\"C:\\Users\\sneha\\OneDrive\\Documents\\test high quality satellite images (.tif)\"\n",
    "deconvolved_dir = r\"C:\\Users\\sneha\\OneDrive\\Documents\\gaussian rl deconvolved test images\"\n",
    "\n",
    "# === Get sorted image filenames ===\n",
    "gt_images = sorted(os.listdir(ground_truth_dir))\n",
    "dc_images = sorted(os.listdir(deconvolved_dir))\n",
    "\n",
    "# === Initialize accumulators ===\n",
    "total_psnr = 0.0\n",
    "total_ssim = 0.0\n",
    "total_lpips = 0.0\n",
    "num_images = len(gt_images)\n",
    "\n",
    "# === Initialize LPIPS model ===\n",
    "lpips_model = lpips.LPIPS(net='vgg').to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lpips_model.eval()\n",
    "\n",
    "# === Loop through images ===\n",
    "for gt_name, dc_name in zip(gt_images, dc_images):\n",
    "    gt_path = os.path.join(ground_truth_dir, gt_name)\n",
    "    dc_path = os.path.join(deconvolved_dir, dc_name)\n",
    "\n",
    "    # Read and convert to RGB\n",
    "    gt_img = cv2.cvtColor(cv2.imread(gt_path), cv2.COLOR_BGR2RGB)\n",
    "    dc_img = cv2.cvtColor(cv2.imread(dc_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize if needed\n",
    "    if gt_img.shape != dc_img.shape:\n",
    "        dc_img = cv2.resize(dc_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "    # === PSNR and SSIM ===\n",
    "    total_psnr += psnr(gt_img, dc_img, data_range=255)\n",
    "    total_ssim += ssim(gt_img, dc_img, data_range=255, channel_axis=-1)\n",
    "\n",
    "    # === LPIPS ===\n",
    "    gt_norm = gt_img.astype(np.float32) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "    dc_norm = dc_img.astype(np.float32) / 127.5 - 1.0\n",
    "\n",
    "    gt_tensor = torch.tensor(gt_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    dc_tensor = torch.tensor(dc_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gt_tensor = gt_tensor.cuda()\n",
    "        dc_tensor = dc_tensor.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_score = lpips_model(gt_tensor, dc_tensor).item()\n",
    "    total_lpips += lpips_score\n",
    "\n",
    "# === Final averages ===\n",
    "avg_psnr = total_psnr / num_images\n",
    "avg_ssim = total_ssim / num_images\n",
    "avg_lpips = total_lpips / num_images\n",
    "\n",
    "print(f\"\\n=== Evaluation over {num_images} images ===\")\n",
    "print(f\"Average PSNR:  {avg_psnr:.2f} dB\")\n",
    "print(f\"Average SSIM:  {avg_ssim:.4f}\")\n",
    "print(f\"Average LPIPS: {avg_lpips:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66006ff-6491-4031-ace7-1e9de18b23cc",
   "metadata": {},
   "source": [
    "#### Paraxial Lens Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99cd4d31-e06c-49ef-8537-fc1f0958f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\sneha\\anaconda\\envs\\gpu_env\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n",
      "\n",
      "=== Evaluation over 77 images ===\n",
      "Average PSNR:  3.79 dB\n",
      "Average SSIM:  0.0844\n",
      "Average LPIPS: 0.2802\n"
     ]
    }
   ],
   "source": [
    "# === Set your directories ===\n",
    "ground_truth_dir = r\"C:\\Users\\sneha\\OneDrive\\Documents\\test high quality satellite images (.tif)\"\n",
    "deconvolved_dir = r\"C:\\Users\\sneha\\OneDrive\\Documents\\paraxial lens rl deconvolved test images\"\n",
    "\n",
    "# === Get sorted image filenames ===\n",
    "gt_images = sorted(os.listdir(ground_truth_dir))\n",
    "dc_images = sorted(os.listdir(deconvolved_dir))\n",
    "\n",
    "# === Initialize accumulators ===\n",
    "total_psnr = 0.0\n",
    "total_ssim = 0.0\n",
    "total_lpips = 0.0\n",
    "num_images = len(gt_images)\n",
    "\n",
    "# === Initialize LPIPS model ===\n",
    "lpips_model = lpips.LPIPS(net='vgg').to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lpips_model.eval()\n",
    "\n",
    "# === Loop through images ===\n",
    "for gt_name, dc_name in zip(gt_images, dc_images):\n",
    "    gt_path = os.path.join(ground_truth_dir, gt_name)\n",
    "    dc_path = os.path.join(deconvolved_dir, dc_name)\n",
    "\n",
    "    # Read and convert to RGB\n",
    "    gt_img = cv2.cvtColor(cv2.imread(gt_path), cv2.COLOR_BGR2RGB)\n",
    "    dc_img = cv2.cvtColor(cv2.imread(dc_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize if needed\n",
    "    if gt_img.shape != dc_img.shape:\n",
    "        dc_img = cv2.resize(dc_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "    # === PSNR and SSIM ===\n",
    "    total_psnr += psnr(gt_img, dc_img, data_range=255)\n",
    "    total_ssim += ssim(gt_img, dc_img, data_range=255, channel_axis=-1)\n",
    "\n",
    "    # === LPIPS ===\n",
    "    gt_norm = gt_img.astype(np.float32) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "    dc_norm = dc_img.astype(np.float32) / 127.5 - 1.0\n",
    "\n",
    "    gt_tensor = torch.tensor(gt_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    dc_tensor = torch.tensor(dc_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gt_tensor = gt_tensor.cuda()\n",
    "        dc_tensor = dc_tensor.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_score = lpips_model(gt_tensor, dc_tensor).item()\n",
    "    total_lpips += lpips_score\n",
    "\n",
    "# === Final averages ===\n",
    "avg_psnr = total_psnr / num_images\n",
    "avg_ssim = total_ssim / num_images\n",
    "avg_lpips = total_lpips / num_images\n",
    "\n",
    "print(f\"\\n=== Evaluation over {num_images} images ===\")\n",
    "print(f\"Average PSNR:  {avg_psnr:.2f} dB\")\n",
    "print(f\"Average SSIM:  {avg_ssim:.4f}\")\n",
    "print(f\"Average LPIPS: {avg_lpips:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b0b0a-868e-44f3-9402-d98221dcbe76",
   "metadata": {},
   "source": [
    "#### Plano Convex Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0228b251-6496-4677-bb6d-49c6265ccd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\sneha\\anaconda\\envs\\gpu_env\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n",
      "\n",
      "=== Evaluation over 77 images ===\n",
      "Average PSNR:  4.00 dB\n",
      "Average SSIM:  0.0836\n",
      "Average LPIPS: 0.2958\n"
     ]
    }
   ],
   "source": [
    "# === Set your directories ===\n",
    "ground_truth_dir = r\"C:\\Users\\sneha\\OneDrive\\Documents\\test high quality satellite images (.tif)\"\n",
    "deconvolved_dir = r\"C:\\Users\\sneha\\OneDrive\\Documents\\plano convex lens rl deconvolved test images\"\n",
    "\n",
    "# === Get sorted image filenames ===\n",
    "gt_images = sorted(os.listdir(ground_truth_dir))\n",
    "dc_images = sorted(os.listdir(deconvolved_dir))\n",
    "\n",
    "# === Initialize accumulators ===\n",
    "total_psnr = 0.0\n",
    "total_ssim = 0.0\n",
    "total_lpips = 0.0\n",
    "num_images = len(gt_images)\n",
    "\n",
    "# === Initialize LPIPS model ===\n",
    "lpips_model = lpips.LPIPS(net='vgg').to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lpips_model.eval()\n",
    "\n",
    "# === Loop through images ===\n",
    "for gt_name, dc_name in zip(gt_images, dc_images):\n",
    "    gt_path = os.path.join(ground_truth_dir, gt_name)\n",
    "    dc_path = os.path.join(deconvolved_dir, dc_name)\n",
    "\n",
    "    # Read and convert to RGB\n",
    "    gt_img = cv2.cvtColor(cv2.imread(gt_path), cv2.COLOR_BGR2RGB)\n",
    "    dc_img = cv2.cvtColor(cv2.imread(dc_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize if needed\n",
    "    if gt_img.shape != dc_img.shape:\n",
    "        dc_img = cv2.resize(dc_img, (gt_img.shape[1], gt_img.shape[0]))\n",
    "\n",
    "    # === PSNR and SSIM ===\n",
    "    total_psnr += psnr(gt_img, dc_img, data_range=255)\n",
    "    total_ssim += ssim(gt_img, dc_img, data_range=255, channel_axis=-1)\n",
    "\n",
    "    # === LPIPS ===\n",
    "    gt_norm = gt_img.astype(np.float32) / 127.5 - 1.0  # Normalize to [-1, 1]\n",
    "    dc_norm = dc_img.astype(np.float32) / 127.5 - 1.0\n",
    "\n",
    "    gt_tensor = torch.tensor(gt_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    dc_tensor = torch.tensor(dc_norm).permute(2, 0, 1).unsqueeze(0).float()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gt_tensor = gt_tensor.cuda()\n",
    "        dc_tensor = dc_tensor.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lpips_score = lpips_model(gt_tensor, dc_tensor).item()\n",
    "    total_lpips += lpips_score\n",
    "\n",
    "# === Final averages ===\n",
    "avg_psnr = total_psnr / num_images\n",
    "avg_ssim = total_ssim / num_images\n",
    "avg_lpips = total_lpips / num_images\n",
    "\n",
    "print(f\"\\n=== Evaluation over {num_images} images ===\")\n",
    "print(f\"Average PSNR:  {avg_psnr:.2f} dB\")\n",
    "print(f\"Average SSIM:  {avg_ssim:.4f}\")\n",
    "print(f\"Average LPIPS: {avg_lpips:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2cf521-2b19-4775-a809-484656f44b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NVIDIA_GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
