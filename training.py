# -*- coding: utf-8 -*-
"""training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qbUo4XoeMx0lciIT0vpyLbCUTrBccYYB

### Import Libraries
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Input, Add, UpSampling2D, Conv2D, Conv2DTranspose, BatchNormalization, Activation, Lambda, Flatten, GlobalAveragePooling2D, Dense, Concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from keras.callbacks import TensorBoard
from skimage.metrics import peak_signal_noise_ratio, structural_similarity


from glob import glob
import os

# Loss Functions
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
import tensorflow.keras.backend as K


gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)

generator_optimizer = Adam(learning_rate=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clipnorm=1.0)
discriminator_optimizer = Adam(learning_rate=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, clipnorm=1.0)

@tf.function
#--- Defining one training step ---
def train_step(blurry_images, sharp_images, critic_updates=5, lambda_gp=10.0):
    """
    Performs one training step for DCGAN using WGAN-GP + Perceptual loss.
    """
    max_grad_norm = 1.0  # Gradient clipping value

    # 1. Train the Discriminator (Critic)
    for _ in tf.range(critic_updates):
        with tf.GradientTape() as disc_tape:
            generated_images = generator(blurry_images, training=True)

            # Critic Output for Real and Fake Images
            real_output = discriminator(sharp_images, training=True)
            fake_output = discriminator(generated_images, training=True)

            # Calculate the Discriminator (Critic) Loss
            disc_loss = discriminator_loss(real_output, fake_output, sharp_images, generated_images)

        # Get the Gradients
        disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

        # Clip Gradients
        disc_gradients = [tf.clip_by_norm(g, max_grad_norm) for g in disc_gradients]

        # Apply Gradients to the Optimizer
        discriminator_optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))

    # 2. Train the Generator
    with tf.GradientTape() as gen_tape:
        generated_images = generator(blurry_images, training=True)

        # Critic Output for Fake Images
        fake_output = discriminator(generated_images, training=True)

        # Calculate the Generator Loss
        gen_loss = generator_loss(fake_output, generated_images, sharp_images)

    # Get the Gradients
    gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)

    # Clip Gradients
    gen_gradients = [tf.clip_by_norm(g, max_grad_norm) for g in gen_gradients]

    # Apply Gradients to the Optimizer
    generator_optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))

    return gen_loss, disc_loss

"""### Load & Preprocess Dataset"""

from google.colab import drive
drive.mount('/content/drive')

# Define Dataset Paths
blurry_images_folder = "/content/drive/My Drive/FYP 2025/gaussian blurred images kernel setting 2" # Import Original Blurry Images or RL Deconvolved Images
sharp_images_folder = "/content/drive/My Drive/FYP 2025/high quality satellite images"

batch_size = 4  # Adjust for available memory

# Get sorted image paths
blurry_image_paths = sorted(glob(os.path.join(blurry_images_folder, "*.png")) +
                                  glob(os.path.join(blurry_images_folder, "*.tif")))
sharp_image_paths = sorted(glob(os.path.join(sharp_images_folder, "*.png")) +
                           glob(os.path.join(sharp_images_folder, "*.tif")))

# Function to load images in batches
def load_images_in_batches(image_paths, batch_size):
    for i in range(0, len(image_paths), batch_size):
        batch_images = []
        for img_path in image_paths[i:i+batch_size]:
            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Read image
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
            img = cv2.resize(img, (256, 256))  # Resize to 256x256
            img = img.astype(np.float32) / 127.5 - 1  # Normalizes to [-1, 1]
            batch_images.append(img)
        yield np.array(batch_images)

# Create TF Datasets
blurry_dataset = tf.data.Dataset.from_generator(
    lambda: load_images_in_batches(blurry_image_paths, batch_size),
    output_signature=tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32)
)

sharp_dataset = tf.data.Dataset.from_generator(
    lambda: load_images_in_batches(sharp_image_paths, batch_size),
    output_signature=tf.TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32)
)

# Zip Blurry Images & Sharp Images
train_dataset = tf.data.Dataset.zip((blurry_dataset, sharp_dataset))
train_dataset = train_dataset.shuffle(100).prefetch(buffer_size=tf.data.AUTOTUNE)

# Debugging
for blurry_images, sharp_images in train_dataset.take(1):
    print(f"Blurry shape: {blurry_images.shape}, Sharp shape: {sharp_images.shape}")

"""#### Define PSNR and SSIM Helper"""

def compute_psnr_ssim(generated_batch, sharp_batch):
    psnr_scores, ssim_scores = [], []

    gen_images = ((generated_batch.numpy() + 1.0) * 127.5).astype("uint8")
    sharp_images = ((sharp_batch.numpy() + 1.0) * 127.5).astype("uint8")

    for gen, sharp in zip(gen_images, sharp_images):
        psnr = peak_signal_noise_ratio(sharp, gen, data_range=255)
        ssim = structural_similarity(sharp, gen, data_range=255, channel_axis=-1)
        psnr_scores.append(psnr)
        ssim_scores.append(ssim)

    return np.mean(psnr_scores), np.mean(ssim_scores)

"""### Training Loop"""

import time
from tqdm import tqdm

# Set up the training hyperparameters
epochs = 40
num_examples_to_generate = 4  # Number of images to generate per epoch

# Fix the dataset shuffling seed for reproducibility
tf.random.set_seed(42)  # Ensures dataset shuffling is the same each time
np.random.seed(42)  # Fix numpy randomness

train_dataset = train_dataset.shuffle(100, seed=42).prefetch(buffer_size=tf.data.AUTOTUNE)

# Extract a deterministic set of blurry images for evaluation
blurry_images_sample = next(iter(train_dataset))[0]  # Get only the first element (blurry images)
seed = blurry_images_sample[:num_examples_to_generate]  # Take a fixed number of images

# Debugging: Ensure correct shape
print(f"Seed shape: {seed.shape}")

# Define directory for saving images
save_dir = "/content/drive/My Drive/FYP 2025/DCGAN/DCGAN_training_epochs"
os.makedirs(save_dir, exist_ok=True)

def denormalize_images(images):
    """Convert images from range [-1,1] back to [0,255] for visualization."""
    if isinstance(images, tf.Tensor):  # Convert Tensor to NumPy if needed
        images = images.numpy()

    images = (images + 1.0) * 127.5  # Correct scaling from [-1,1] to [0,255]
    return np.clip(images, 0, 255).astype(np.uint8)  # Ensure valid range

def generate_and_plot_images(model, epoch, test_input):
    """
    Generate images using the generator and plot them.
    """
    predictions = model(test_input, training=False)  # Generate images

    # Debug: Print min/max values before denormalization
    print(f"Before denormalization: min={tf.reduce_min(predictions).numpy()}, max={tf.reduce_max(predictions).numpy()}")

    predictions = denormalize_images(predictions)  # Convert [-1,1] â†’ [0,255]

    # Debug: Print min/max values after denormalization
    print(f"After denormalization: min={np.min(predictions)}, max={np.max(predictions)}")

    # Ensure valid image range
    predictions = np.clip(predictions, 0, 255).astype(np.uint8)

    # Resize images to 1028x1028
    # predictions_resized = np.array([cv2.resize(img, (1028, 1028), interpolation=cv2.INTER_CUBIC) for img in predictions])

    # print(f"Predictions Resized Shape: {predictions_resized.shape}")  # Debugging output

    fig, axes = plt.subplots(1, predictions.shape[0], figsize=(12, 12))  # Ensure figure size

    for i, ax in enumerate(axes):
        ax.imshow(predictions[i])  # Display each image
        ax.axis('off')

    plt.tight_layout()

    save_path = os.path.join(save_dir, f'image_at_epoch_{epoch:04d}.png')
    plt.savefig(save_path)

    # Debug: Print confirmation that image was saved
    print(f"Image saved at: {save_path}")

    plt.show()

def train(dataset, epochs):
    gen_loss_list = []
    disc_loss_list = []
    real_score_list = []
    fake_score_list = []
    psnr_list = []
    ssim_list = []

    num_images = len(blurry_image_paths)
    num_batches = num_images // batch_size
    if num_images % batch_size != 0:
        num_batches += 1

    for epoch in tqdm(range(epochs)):
        start = time.time()
        print(f'Training started for epoch {epoch + 1} with {num_batches} batches..')

        total_gen_loss = 0
        total_disc_loss = 0
        total_psnr = 0
        total_ssim = 0

        for blurry_images, sharp_images in dataset:
            gen_loss, disc_loss = train_step(blurry_images, sharp_images)

            generated_images = generator(blurry_images, training=False)
            batch_psnr, batch_ssim = compute_psnr_ssim(generated_images, sharp_images)

            total_gen_loss += gen_loss
            total_disc_loss += disc_loss
            total_psnr += batch_psnr
            total_ssim += batch_ssim

        # Compute mean losses per epoch
        mean_gen_loss = total_gen_loss / num_batches
        mean_disc_loss = total_disc_loss / num_batches
        mean_psnr = total_psnr / num_batches
        mean_ssim = total_ssim / num_batches

        print(f"Epoch {epoch+1}: Gen Loss={mean_gen_loss:.4f}, PSNR={mean_psnr:.2f} dB, SSIM={mean_ssim:.4f}")

        generate_and_plot_images(generator, epoch + 1, seed)

        gen_loss_list.append(mean_gen_loss)
        disc_loss_list.append(mean_disc_loss)
        psnr_list.append(mean_psnr)
        ssim_list.append(mean_ssim)

        if (epoch + 1) % 10 == 0:
            checkpoint_path = os.path.join(save_dir, f"generator_epoch_{epoch+1}.keras")
            generator.save(checkpoint_path)
            print(f"Checkpoint saved at: {checkpoint_path}")

        print(f'Time for epoch {epoch+1} is {time.time() - start:.2f} sec')

    return gen_loss_list, disc_loss_list, real_score_list, fake_score_list, psnr_list, ssim_list

gen_loss_epochs, disc_loss_epochs, real_score_list, fake_score_list, psnr_scores, ssim_scores = train(train_dataset, epochs=epochs)

"""#### END"""